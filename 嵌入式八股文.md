
### 1.static作用，变量加入static以后在内存中存储位置的变化。

在 C/C++ 中，static 关键字可以用于局部变量和全局变量，以及函数。

全局变量：当一个全局变量被声明为 static 时，它的作用域被限制在声明它的文件内，即它变成了文件作用域（或内部链接性）。但是，在内存中的存储位置并没有直接变化，它仍然存储在程序的静态数据区（或全局/静态存储区）。 局部变量：当一个局部变量被声明为 static 时，它的生命周期贯穿整个程序执行期间，但其作用域仍然限制在声明它的函数或代码块内。在内存中，这样的变量也是存储在静态数据区，而不是像普通的局部变量那样存储在栈上。这意味着，即使函数执行完毕，这个 static 局部变量的值也不会丢失，下次函数被调用时，这个变量的值仍然存在。 函数：当一个函数被声明为 static 时，它的作用域也被限制在声明它的文件内，即它不能被其他文件直接访问。

普通的局部变量创建后是放在栈区中，这种局部变量进入作用域时创建，出了作用域就销毁；

但static修饰后的局部变量则放在静态区中，它改变了局部变量的存储位置，从而使得变量的生命周期延长，延长至程序结束才销毁。

### 2.volatile作用

在C语言中，volatile 关键字是一种类型修饰符，用于告诉编译器该变量的值可能会在程序控制之外被改变。这意味着，每次访问这个变量时，编译器都必须从内存中重新读取它的值，而不是使用可能已经缓存在寄存器中的值。

volatile 的主要用途是处理那些可能会被异步事件（如中断服务例程、硬件寄存器访问等）改变的内存位置。如果不使用 volatile 关键字，编译器在优化代码时可能会认为变量的值在两次访问之间不会改变，因此可能会将变量的值缓存在寄存器中，而不是每次都从内存中读取。这可能会导致程序无法正确感知到变量值的实际变化，从而引发错误。

在C/C++中，内存主要分为以下几个区域：

栈区（Stack）： 主要用于存储函数的局部变量和函数调用的上下文信息。 由编译器自动分配和释放，遵循后进先出（LIFO）的原则。 栈空间的大小有限，可以通过系统命令（如Linux下的ulimit -s）来查看和修改。 堆区（Heap）： 用于动态分配内存，即程序运行时手动申请和释放的内存。 需要程序员手动管理，使用malloc/free（C语言）或new/delete（C++语言）来分配和释放内存。 堆区内存空间几乎没有限制，但容易产生内存碎片。 全局/静态存储区： 存放全局变量和静态变量。 全局变量在程序启动时被创建，在程序的整个运行期间都存在，直到程序结束才被销毁。 静态变量在声明时使用static关键字修饰，它们在程序运行前会被初始化，其内存空间也在程序的整个生命周期内保持不变。 文字常量区： 存放常量，且不允许修改。 程序结束后由系统释放。 程序代码区： 存放程序的二进制代码，包括指令和函数实现。 通常是只读的，程序在运行时不能修改代码段的内容。

### 3.C++为什么有指针还要引用，为什么不和JAVA一样抛弃指针

C++设计之初就考虑到了效率、灵活性和与C语言的兼容性，这导致了它在内存管理方面提供了指针这一强大的工具。尽管指针提供了极高的灵活性和控制力，但它们也带来了复杂性，比如需要手动管理内存（分配和释放）、指针解引用时的错误检查（如空指针解引用）、以及指针运算可能导致的安全问题等。

为了在一定程度上缓解这些问题，C++引入了引用的概念。引用是C++中的一个高级特性，它提供了一种访问变量的方式，这种方式在语法上类似于指针，但在使用上更加安全和方便。引用在定义时必须被初始化，并且一旦被初始化后就不能再指向另一个对象（即引用不能重新绑定）。这些特性使得引用在函数参数传递、返回值以及访问类的成员时非常有用，因为它们避免了指针可能带来的混淆和错误。

然而，C++并没有完全抛弃指针，因为指针在某些情况下是必需的，比如：

动态内存管理：C++允许通过new和delete操作符动态地分配和释放内存，这些操作返回的是指向分配的内存的指针。 数组和字符串：在C++中，数组名在大多数情况下会被视为指向数组首元素的指针，而字符串则通常通过字符指针（或字符数组）来表示。 底层系统编程：在进行底层系统编程时，如操作系统开发、嵌入式系统开发等，指针是访问和操作硬件资源的基本工具。 性能优化：在某些情况下，使用指针可以绕过C++的类型安全检查和封装，直接操作内存，从而达到性能优化的目的。 相比之下，Java之所以没有指针，是因为Java的设计哲学之一是“安全优先”。Java通过自动内存管理（垃圾回收机制）来避免内存泄漏和指针悬挂等问题，同时提供了丰富的类库来简化编程。然而，这种设计也带来了一定的性能开销，因为垃圾回收机制需要额外的CPU和内存资源来运行。

因此，C++保留指针并引入引用的做法，既保证了语言的灵活性和效率，又在一定程度上提高了安全性。这使得C++成为了一个既强大又复杂的编程语言，适合用于需要高性能、高灵活性和高控制力的应用场景。

### 4.delete和delete[]的区别

在C++中，delete 和 delete[] 是用于释放动态分配的内存的两个关键字，它们之间的主要区别在于它们被用于释放不同类型的动态内存。

delete： 用于释放单个对象所占用的内存。 如果你使用 new 关键字为一个对象动态分配了内存，那么你应该使用 delete 来释放这块内存。 如果尝试用 delete 来释放一个用 new[] 分配的内存块（即一个对象数组），那么结果是未定义的，很可能导致程序崩溃或内存泄漏。

delete[]： 用于释放一个对象数组所占用的内存。 如果你使用 new[] 关键字为一个对象数组动态分配了内存，那么你应该使用 delete[] 来释放这块内存。 如果尝试用 delete[] 来释放一个用 new 分配的内存块（即一个单个对象），虽然编译器可能不会直接报错，但这也是不推荐的，因为它可能不会按预期工作（特别是在复杂类型上，如包含动态分配成员的类）。

### 5.虚函数是用来干嘛的？虚函数机制怎么实现的？虚表指针在内存中的存放位置？多态实现的原理

虚函数的作用 虚函数在C++中主要用于实现多态性。它允许在基类中声明并在派生类（子类）中重写成员函数，以便通过基类类型的指针或引用调用派生类对象的成员函数时，能够根据实际对象的类型来决定调用哪个版本的函数。这样，程序在运行时可以根据对象的实际类型来决定调用哪个函数，从而表现出不同的行为。

具体来说，虚函数的主要作用包括：

允许在派生类中重写基类的函数，实现特定于派生类的行为。 通过基类类型的指针或引用来访问派生类对象的特定成员函数，而无需知道实际对象的具体类型，提高了代码的灵活性和可扩展性。 支持多级继承中的动态绑定，当派生类继承自多个基类时，可以通过基类类型的指针或引用来访问派生类对象的成员函数，实现对不同基类的多态调用。 虚函数机制的实现 虚函数机制的实现主要依赖于虚函数表（vtable）和虚函数表指针（vptr）。

虚函数表（vtable）： 虚函数表是一个存储指向类虚函数指针的数组。 每个包含虚函数的类都有一个对应的虚函数表，该表在编译时创建，并存储在程序的只读数据段（.rodata）中，即C++内存模型中的常量区。 虚函数表中的元素按照虚函数在类中的声明顺序排列，每个元素都是一个指向对应虚函数实现的指针。 虚函数表指针（vptr）： 虚函数表指针是一个指向类虚函数表的指针，它属于对象实例的一部分。 对于含有虚函数的类，编译器会在对象内存布局的最前面（或特定位置，取决于编译器的实现）添加一个虚函数表指针。 当通过基类类型的指针或引用来调用虚函数时，程序会通过这个虚函数表指针找到对应的虚函数表，并根据对象的实际类型来调用相应的函数。 虚表指针在内存中的存放位置 虚表指针（vptr）在内存中的存放位置通常位于对象内存布局的最前面（或特定位置），但具体位置取决于编译器的实现。对于通过new操作符动态分配的对象，虚表指针位于堆内存中；对于在栈上声明的对象，虚表指针则位于栈内存中。

### 6.C++多态怎么理解？C++有哪些多态的典型例子？

C++中的多态性（Polymorphism）是指允许一个接口被多种类型的对象所实现，或者说一个接口可以有多种不同的实现方式。这是面向对象编程的三大特性之一，另外两个是封装和继承。多态性使得程序在运行时能够根据对象的实际类型执行对应的方法，从而增加了代码的灵活性和可扩展性。

在C++中，多态性主要通过虚函数（Virtual Function）来实现。虚函数允许在派生类中重新定义基类中的函数，这样当使用基类指针或引用调用该函数时，将会调用相应对象类型的函数实现，而不是基类的实现。

虚函数实现多态性外，C++还支持通过纯虚函数实现抽象类和接口，进一步增强了多态性的应用。纯虚函数是一种在基类中声明但没有实现的虚函数，它强制派生类提供具体的实现。包含纯虚函数的类是抽象类，不能被实例化，只能作为基类来派生其他类。这使得我们可以定义一组具有共同行为的类，并通过这些类的共同接口来操作它们，从而实现多态性。

### 7.叙述程序编译都包含哪些阶段，每个阶段干了什么？

C/C++程序编译包含以下四个阶段：预处理、编译、汇编和链接。每个阶段的具体作用如下：

​ 预处理阶段： 预处理器根据以字符#开头的命令，修改原始的C/C++程序。例如，处理#include指令，将头文件的内容插入到程序中；处理#define指令，进行宏替换；根据条件编译指令（如#ifdef、#ifndef等）决定是否编译某部分代码。此外，预处理器还会去除注释和将分行的代码行连接成一整行。这一阶段生成的输出文件通常是.i文件。 ​ 编译阶段： 编译器读取预处理后的源代码，进行词法分析和语法分析，将其分解成单词（token）并转换成词法单元，然后生成语法树。接着进行语义分析，检查代码是否符合语言的语法规范，包括数据类型匹配、符号定义等。之后，编译器会对代码进行优化，例如去除无用代码、利用CPU指令优化等。最后，根据中间代码生成目标代码，这通常是汇编语言代码，保存在.s文件中。 ​ 汇编阶段： 汇编器将编译阶段生成的汇编语言代码转换成机器语言指令。它会处理符号，将符号关联到它们所在的位置，并转化为合适的地址。汇编器还会生成对应的机器指令集，包括操作码、数据存储方式等，并确保生成的指令集与中间代码等价。此外，汇编器会进行数据处理，将程序中使用的数据分配到内存空间中。最终，汇编器会生成一个二进制的目标文件（.o文件），其中包含了可执行程序的机器指令和数据。 ​ 链接阶段： 链接器负责将多个目标文件和库文件链接成一个可执行文件。它进行地址重定位，将每个目标文件中的地址转换成相对于全局起始地址的地址。链接器还解决目标文件之间的符号引用问题，例如函数和变量的引用。如果多个目标文件中定义了相同的符号，链接器会进行合并和去重。此外，如果程序使用了动态库，链接器还需要加载这些库并将符号引用关联到库中的符号实现。最终，链接器生成一个可执行文件，供操作系统加载和执行。CMake是如何包含文件目录的

### 8.全局变量和局部变量在什么地方？堆栈如何申请资源？

在C/C++程序中，全局变量和局部变量存储在程序的不同内存区域中，这些区域包括数据段、堆和栈。下面是它们各自的位置： 全局变量： 全局变量通常存储在程序的数据段中。数据段是程序在内存中为全局变量和静态变量分配的区域。全局变量在程序启动时分配内存，并在程序结束时释放。 如果全局变量是初始化的（即，在声明时给定了初值），那么它通常存储在数据段的一个子区域——初始化数据段中。 如果全局变量未初始化，它可能被放置在另一个子区域——未初始化数据段（通常称为BSS段，代表Block Started by Symbol）中。 局部变量： 局部变量（包括函数内的自动变量）通常存储在栈上。当函数被调用时，会在栈上为局部变量分配空间，并在函数返回时释放这些空间。 栈是一种后进先出（LIFO）的数据结构，用于存储临时变量、返回地址和函数调用过程中保存的寄存器值。 关于堆栈如何申请资源： 栈：栈内存的管理是自动的，由编译器和运行时环境负责。每当一个函数被调用时，编译器会自动在栈上为该函数的局部变量分配空间。当函数返回时，这些空间会被自动释放。程序员无需显式地申请或释放栈内存。 堆：与栈不同，堆内存的管理需要程序员的显式参与。在C语言中，使用malloc、calloc或realloc函数来动态分配堆内存，并使用free函数来释放这些内存。在C++中，可以使用new操作符来分配内存，并使用delete操作符来释放内存。堆内存的申请和释放必须谨慎处理，以避免内存泄漏或内存碎片等问题

### 9.C语言编译后的内存分布

C语言编译后的内存分布主要包括以下几个区域：

​ 栈（Stack）：由编译器自动分配和释放，用于存放函数调用过程中的各种参数、局部变量、返回值以及函数返回地址。其操作方式类似于数据结构中的栈。 ​ 堆（Heap）：用于程序动态申请分配和释放空间。C语言中的malloc和free、C++中的new和delete均是在堆中进行的。程序员申请的空间在使用结束后应该释放，若程序员没有释放空间，则程序结束时系统自动回收。 全局（静态）存储区：全局存储区分为DATA段和BSS段。DATA段（全局初始化区）存放初始化的全局变量和静态变量； ​ BSS段（全局未初始化区）存放未初始化的全局变量和静态变量。在程序执行前，BSS段会被系统自动清0，所以未初始化的全局变量和静态变量在程序执行之前已经为0。程序运行结束时，该区域内存会被自动释放。 ​ 文字常量区：存放常量字符串。程序结束后由系统释放。 ​ 程序代码区：用于存放程序的二进制代码。

### 10.函数调用的过程

C/C++函数调用的过程主要包括以下几个步骤：

​ 函数调用前的准备： 在调用函数之前，程序需要先执行函数调用之前的语句。 编译器会检查函数的声明和定义是否匹配，以确保函数调用的正确性。 ​ 参数传递： 当程序遇到函数调用语句时，会先将当前的执行流程暂停，然后跳转到该函数的入口处。 在跳转之前，需要将函数的参数按照参数列表的顺序压入栈中，以便函数内部能够访问这些参数。 ​ 函数执行： 程序跳转到函数的入口处开始执行函数体中的代码。 在函数体内，可以使用局部变量来存储临时数据。这些局部变量仅在函数内部有效，并在函数执行完毕后被销毁。 函数体内的代码按照顺序执行，直到遇到return语句或函数结束。 ​ 返回值传递： 如果函数有返回值，那么在函数执行完毕后，该值会被保存在寄存器或特定的内存位置中。 调用者可以从该位置获取返回值，并进行后续的处理。 ​ 恢复现场并返回调用者： 函数执行完毕后，需要恢复之前保存的现场信息，包括程序计数器、栈指针等寄存器的值。 然后将程序计数器设置为返回地址，并跳转到调用者处继续执行。 这个过程涉及到栈的操作，因为栈是一种后进先出的数据结构，非常适合用于函数调用过程中的信息保存和恢复。在函数调用时，相关的信息（如参数、返回地址、局部变量等）被压入栈中；在函数执行完毕后，这些信息被弹出栈，从而恢复到函数调用前的状态。

### 11.静态局部变量存储在静态区，那么静态区的创建和消失是在什么时候?

C/C++中的静态局部变量存储在静态区（也称为全局数据区或数据段）。关于静态区的创建和消失时间，可以归纳如下：

​ 创建时间：静态区在程序开始执行时就被创建。这意味着，当程序启动时，操作系统会为程序分配内存空间，其中包括静态区。静态局部变量在这一阶段就被分配了内存，并且只会被初始化一次。 ​ 消失时间：静态区的内存会在程序结束时被释放。也就是说，当程序执行完毕，操作系统会回收分配给程序的内存空间，包括静态区。因此，静态局部变量会在程序结束时被销毁。

### 12. 多进程的内存管理问题

C/C++多进程的内存管理问题主要涉及以下几个方面：

​ 独立的地址空间： 每个进程在操作系统中拥有独立的地址空间。这意味着每个进程看到的内存地址是独立的，一个进程不能直接访问另一个进程的内存地址。 ​ 内存隔离： 多进程环境中，各个进程的内存是隔离的。这种设计提供了数据的安全性和完整性，因为一个进程中的错误不会影响到其他进程。 ​ 进程间通信(IPC)： 由于内存隔离，进程间通信变得必要。有多种IPC机制，如管道、消息队列、信号、共享内存、套接字等，可用于数据交换和同步。 ​ 共享内存的使用： 尽管进程内存是隔离的，但有时为了实现某些功能，需要使用共享内存。共享内存允许两个或多个进程共享一个给定的存储区。然而，这需要谨慎的同步机制来避免数据竞争。 ​ 资源管理和内存泄漏： 在多进程环境中，每个进程应独立管理其资源，并在进程结束时释放资源，以防止内存泄漏。 ​ 写时复制（Copy-On-Write）： 在创建新进程（如通过fork()系统调用）时，许多操作系统使用写时复制技术来优化资源使用。这意味着父子进程最初共享相同的物理内存页面，但当其中一个进程尝试修改这些页面时，系统会复制该页面，以确保每个进程都有其自己的数据副本。

### 13. 静态局部变量与局部变量的区别？为什么局部变量未定义时，每次初始化的结果是不确定的？是个真随机数还是个伪随机数？

C/C++中的静态局部变量与普通局部变量之间有几个关键的区别：

​ 存储位置和生命周期： 静态局部变量：存储在静态存储区（不在栈上），生命周期为整个程序的运行时间。它们在程序开始运行时被创建，在程序结束时被销毁。 局部变量：存储在栈上，生命周期仅限于其所在的代码块（例如函数）的执行期间。当函数被调用时，局部变量被创建，并在函数返回后被销毁。 ​ 初始化： 静态局部变量：只会被初始化一次，且如果在代码中没有显式初始化，它们会被自动初始化为0（对于基本数据类型）。 局部变量：每次函数被调用时都会被重新创建和初始化。如果局部变量没有被显式初始化，它们的初始值是未定义的。 可见性：无论是静态局部变量还是普通局部变量，它们的可见性都限于定义它们的代码块内（通常是函数内部）。

​ 关于局部变量未定义时初始化的结果是不确定的问题，这并不是因为它们是“随机数”，而是因为局部变量在栈上分配，而栈空间在函数被调用之前可能包含任何值。当局部变量被创建时，它们只是简单地占据了栈上的某个位置，而没有进行显式的初始化。因此，这些变量的初始值取决于它们之前栈空间中的内容，这是不确定的。 ​ 这种不确定性不是由于任何随机数生成机制造成的，而是因为局部变量没有被赋予一个明确的初始值。它们既不是真随机数也不是伪随机数；它们只是简单地反映了栈上之前存储的数据。在C/C++中，使用未初始化的局部变量是危险的，因为它们可能包含任何值，这可能导致程序行为不可预测。 ​ 为了避免这种情况，最佳实践是始终初始化局部变量，或者使用C++11引入的列表初始化语法来确保所有元素都被初始化。在C语言中，可以使用memset或其他方法来显式地设置变量的初始值。

### 14.嵌入式中栈的工作机制

嵌入式系统中栈的工作机制主要涉及以下几个方面：

​ 存储结构：栈是一种特殊的数据结构，它遵循后进先出（LIFO，Last In First Out）的原则。在嵌入式系统中，栈通常用于存储局部变量、函数参数、返回地址等信息。这些信息在函数调用时被推入栈中，并在函数执行完毕后从栈中弹出。 ​ 内存管理：栈内存是由编译器自动分配和释放的。每当函数被调用时，编译器会自动为该函数分配一块内存，这块内存就是栈内存。栈内存的大小是有限的，受系统资源和操作系统限制。 ​ 函数调用与栈帧：每次函数调用时，会创建一个栈帧来存储该函数的局部变量、参数、返回地址等信息。这个栈帧在函数调用结束后会被自动释放。这就是为什么局部变量只在函数内部有效，一旦函数执行完毕，这些变量就会被销毁。 ​ 使用注意事项：由于栈的大小是有限的，因此需要注意避免栈溢出。栈溢出可能会导致程序崩溃或不可预测的行为。为了避免这种情况，程序员应该合理估计每个函数所需要的栈空间，并合理设置栈的大小。

### 15.struct字节对齐

以下是关于C/C++结构体字节对齐的一些关键点：

​ 默认对齐值：每个数据类型都有一个默认的对齐值，这通常与其大小相关。例如，一个char类型可能对齐到1字节边界，int类型可能对齐到4字节边界（这取决于平台和编译器）。 ​ 结构体对齐：结构体的对齐要求通常取其成员中最大对齐值的整数倍。例如，如果一个结构体包含char和int类型，且int的对齐要求是4字节，那么整个结构体的对齐要求可能也是4字节。 ​ 填充字节：为了满足对齐要求，编译器可能会在结构体的成员之间插入填充字节。这些填充字节不存储任何有效数据，只是为了确保后续成员的对齐。 ​ #pragma pack指令：在某些编译器中，可以使用#pragma pack指令来控制结构体的对齐。例如，#pragma pack(1)会强制编译器按1字节对齐，从而消除填充字节并减小结构体的大小。但这样做可能会导致性能下降，因为非对齐的内存访问通常更慢。 ​ 显式对齐：在C11和C++11及更高版本中，可以使用_Alignas关键字（C++中为alignas）来显式指定对齐要求。 ​ 跨平台考虑：不同的处理器和操作系统可能有不同的对齐要求。在编写跨平台代码时，需要特别注意这一点，以确保代码在所有目标平台上都能正确运行。 ​ 内存占用和性能权衡：通过调整对齐设置，可以在内存占用和性能之间找到平衡点。紧密的对齐可以节省内存，但可能导致性能下降；而宽松的对齐可能会浪费一些内存，但可以提高访问速度。

```c
struct Example {  
    char a;   // 1 byte  
    // 这里可能会有3个填充字节，取决于编译器的对齐设置  
    int b;    // 4 bytes  
};
```

### 16.容器了解吗？vector实现的机制是怎样的？

C++标准库提供了一系列的容器类，用于存储和管理数据集合，如vector、list、deque、set、map等。这些容器提供了丰富的接口和功能，使得数据操作变得更加简单和高效。

关于vector的实现机制，以下是一些关键点：

​ 动态数组：vector是一个动态数组，它可以根据需要自动调整大小。当向vector中添加元素时，如果当前已分配的内存空间不足以容纳新元素，vector会自动重新分配更大的内存空间，并将原有元素复制到新的内存空间中。 连续内存存储：vector中的元素在内存中是连续存储的。这种存储方式使得访问vector中的元素非常高效，因为可以通过简单的索引计算直接定位到元素的内存地址。 ​ 容量和大小：vector有两个重要的属性：容量（capacity）和大小（size）。容量表示vector当前分配的内存空间可以容纳的元素数量，而大小表示vector中实际存储的元素数量。当大小超过容量时，vector会进行内存重新分配和元素复制操作。 ​ 内存重新分配策略：当需要扩大vector的容量时，通常会分配一个更大的内存空间，而不是仅仅增加足够的空间来存储新元素。这是为了减少频繁的内存分配和复制操作，提高效率。具体的内存分配策略可能因实现而异，但通常会考虑到性能和内存使用效率之间的平衡。 ​ 迭代器失效问题：由于vector在内存重新分配时可能会改变元素的存储位置，因此在使用迭代器遍历或操作vector时需要特别注意。在内存重新分配后，之前获取的迭代器可能会失效，因此需要谨慎处理。

### 17.迭代器有了解吗？讲解一下你的理解

​ 定义与功能： 迭代器是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素。每个迭代器对象代表容器中的确定的地址，提供了一种方法来访问容器中的元素，而无需暴露该容器的底层表示。简言之，迭代器充当了容器和算法之间的中介，使得算法能够独立于具体的容器实现进行操作。 ​ 类型与分类： C/C++提供了多种类型的迭代器，如输入迭代器、输出迭代器、前向迭代器、双向迭代器和随机访问迭代器，它们各自具有不同的功能和效率。 例如，在C++ STL中，有begin()和end()这样的成员函数，分别返回指向容器第一个元素和容器末尾（最后一个元素之后的位置）的迭代器。 ​ 使用场景： 迭代器通常与循环结构一起使用，用于遍历并操作容器中的元素。通过使用迭代器，我们可以顺序地访问容器中的每个元素，并进行读取或修改操作。 ​ 优点： 迭代器提供了一种抽象的方式来处理容器中的元素，使得算法可以更加通用和灵活。 通过使用迭代器，我们可以将算法与特定的容器实现解耦，从而提高代码的可重用性和可维护性。 ​ 注意事项： 在使用迭代器时需要注意迭代器的有效性。例如，在遍历过程中如果修改了容器（如添加或删除元素），可能会导致迭代器失效。 不同类型的容器可能支持不同类型的迭代器，因此在使用前应查阅相关文档以了解正确的迭代器类型和使用方法。

### 18.内存分配函数

内存分配函数在C语言中通常指的是malloc、calloc和realloc等函数，在C++中则可能包括new操作符。这些函数或操作符用于在运行时动态地分配内存。

### 19.不同位数编译器下的基本数据类型所占的字节数

1、16位编译器 char ：1个字节 char*(即指针变量): 2个字节 short int : 2个字节 int： 2个字节 unsigned int : 2个字节 float: 4个字节 double: 8个字节 long: 4个字节 long long: 8个字节 unsigned long: 4个字节

2、32位编译器 char ：1个字节 char*（即指针变量）: 4个字节

（32位的寻址空间是2^32, 即32=8*4个bit，也就是4个字节。同理64位编译器） short int : 2个字节 int： 4个字节 unsigned int : 4个字节 float: 4个字节 double: 8个字节 long: 4个字节 long long: 8个字节 unsigned long: 4个字节

3、64位编译器 char ：1个字节 char*(即指针变量): 8个字节 short int : 2个字节 int： 4个字节 unsigned int : 4个字节 float: 4个字节 double: 8个字节 long: 8个字节 long long: 8个字节 unsigned long: 8个字节

### 20堆和栈有什么区别？

堆和栈是计算机中两种常用的内存数据结构，它们之间存在几个主要的区别：

数据结构：栈是一种线性结构，遵循后进先出（LIFO）的原则，其操作只能在一端（称为栈顶）进行，如插入（进栈）和删除（出栈）。而堆是一种树形结构，通常可以被看作一棵完全二叉树，且满足堆中某个结点的值总是不大于或不小于其父结点的值。 内存分配方式：栈采用的是静态内存分配，其大小在编译时就已经确定，由系统自动分配和释放。相反，堆采用的是动态内存分配，程序可以在运行时请求分配任意大小的内存空间，并需要在不使用时手动释放。 存储内容：栈中主要存储的是函数的调用和局部变量，这些变量只在函数执行期间存在，并在函数返回后被销毁。而堆中存储的是对象的实例，这些对象可以在程序的多个部分之间共享，并且其生命周期不依赖于创建它们的函数或方法。

### 21虚函数和纯虚函数区别

虚函数（Virtual Function）和纯虚函数（Pure Virtual Function）在C++中都是多态性的关键组成部分，但它们之间存在一些关键的区别。

虚函数 定义：虚函数是在基类中声明并在派生类中可以重写的函数。它允许通过基类的指针或引用来调用派生类中的函数实现。 实现：虚函数在基类中可以有实现（即函数体），派生类可以选择重写这个函数，也可以不重写而继承基类的实现。 用途：虚函数主要用于实现多态性，使得基类指针或引用能够指向派生类的对象，并调用派生类中相应的重写函数。 实例化：包含虚函数的类可以被实例化。 纯虚函数 定义：纯虚函数是在基类中声明的，但没有具体实现的函数。它在函数声明的末尾加上= 0来标记。 实现：纯虚函数在基类中没有实现（即没有函数体），它要求派生类必须提供该函数的实现。 用途：纯虚函数主要用于定义接口，它强制派生类必须实现该函数，从而提供了一种实现多态和接口继承的方式。 实例化：包含纯虚函数的类被称为抽象基类（或接口类），它不能被实例化。只有当所有的纯虚函数都被派生类实现后，派生类才能被实例化。 区别总结 实现：虚函数可以有实现，而纯虚函数没有实现。 派生类要求：虚函数不要求派生类提供实现，而纯虚函数要求派生类必须提供实现。 实例化：包含虚函数的类可以被实例化，而包含纯虚函数的类（抽象基类）不能被实例化。 用途：虚函数主要用于实现多态性，而纯虚函数主要用于定义接口和实现抽象基类。

### 22.编译过程

GCC 编译器的编译流程是：预处理、编译、汇编和链接。预处理就是展开所有的头文件、替换程序中的宏、解析条件编译并添加到文件中。编译是将经过预编译处理的代码编译成汇编代码，也就是我们常说的程序编译。汇编就是将汇编语言文件编译成二进制目标文件。链接就是将汇编出来的多个二进制目标文件链接在一起，形成最终的可执行文件，链接的时候还会涉及到静态库和动态库等问题。

### 2.ARM架构相关及STM32

### 1.RISC和CISC

RISC（Reduced Instruction Set Computer，精简指令集计算机）和CISC（Complex Instruction Set Computer，复杂指令集计算机）是两种不同类型的计算机架构。它们在设计理念、指令集复杂度、硬件设计、执行速度以及应用领域等方面存在显著差异。

设计理念： RISC的设计理念是简化指令集，提高指令执行速度。它强调通过减少指令的复杂性来加快处理器的速度，并简化硬件设计。 CISC的设计理念则是提供丰富的指令集，以支持更复杂的操作和编程任务。它旨在通过提供多功能指令来简化编程和提高程序员的效率。 指令集复杂度： RISC的指令集相对简单，每条指令通常只完成一个基本操作，如加载、存储或运算。这有助于加快指令的执行速度。 CISC的指令集更为复杂，一条指令可以完成多个操作。这种复杂性使得编程更加方便，但可能会影响执行速度。 硬件设计： RISC的硬件设计相对简单，因为指令集的简化降低了硬件的复杂性。这有助于减少设计成本和提高可靠性。 CISC则需要更复杂的硬件设计来支持其复杂的指令集。这可能会增加设计成本和功耗。 执行速度： 由于RISC的指令更简单，因此其执行速度往往更快。此外，RISC架构通常采用流水线技术，可以进一步提高执行效率。 CISC可能需要更多的周期来执行复杂的指令，这可能会影响其整体执行速度。

### 2.MCU可以运行Linux吗，为什么

主要是MMU的问题

### 3.STM32启动过程（上电开始->main执行的过程）

STM32的启动过程从上电开始到main函数的执行，大致可以归纳为以下几个步骤：

​ 上电复位：当STM32设备上电或复位后，处理器会自动根据向量表偏移地址找到向量表。向量表通常位于Flash的起始地址（如0x08000000），其中包含栈顶指针（MSP）和复位向量的地址。处理器会将MSP的初始值（由编译器生成，是主堆栈的初始值）和复位向量的地址分别加载到SP（堆栈指针）和PC（程序计数器）中。 ​ 时钟初始化：随后，处理器跳转到复位中断服务程序Reset_Handler，该程序会调用SystemInit函数进行系统时钟的初始化。 ​ 跳转到main：初始化系统时钟后，程序会执行到指令LDR R0, =main，然后就跳转到main程序段运行。main是标准库中的函数，不是用户编写的main函数，但会负责调用用户编写的main函数。 ​ 初始化数据段和堆栈：在__main函数中，会进行RW、ZI数据段的重定位工作，即将ROM中的RW数据拷贝到RAM中，将ZI段清零。同时，也会进行堆栈的初始化。 ​ 跳转到main函数：完成上述初始化工作后，程序最终会跳转到用户编写的main函数，开始执行用户程序。

```text
Reset_Handler    PROC
                 EXPORT  Reset_Handler             [WEAK]
     IMPORT  __main
     IMPORT  SystemInit
                 LDR     R0, =SystemInit
                 BLX     R0
                 LDR     R0, =__main
                 BX      R0
                 ENDP
```

### 4.arm处理中断的寄存器

1. 外部中断寄存器 对于外部中断，ARM处理器通常通过特定的引脚或端口接收中断信号。这些中断信号的处理涉及到一组控制外部中断的寄存器，包括但不限于：

EXTINTx（外部中断控制寄存器）：用于设置外部中断的触发方式，如上升沿触发、下降沿触发或高/低电平触发。 EINTFLTx（外部中断滤波控制寄存器）：控制外部中断信号的滤波时钟和滤波宽度，以减少因信号抖动或噪声引起的误触发。 EINTPEND（外部中断挂起寄存器）：当一个外部中断发生时，相应的位会被置1。清除该寄存器中的位需要写入1。 EINTMASK（外部中断屏蔽寄存器）：用于屏蔽或使能外部中断。当某位为1时，相应的中断被屏蔽。

1. 内部中断寄存器 内部中断的处理则依赖于一系列内部寄存器，这些寄存器控制中断的识别、优先级排序和响应。以下是一些关键的内部中断寄存器：

SUBSRCPND（子源挂起寄存器）：当某个带子中断的内部中断发生时，相应的位会被置1。 INTSUBMSK（子中断屏蔽寄存器）：用于屏蔽或使能带子中断的内部中断。 SRCPND（源挂起寄存器）：当任何中断发生时，相应的位会被置1，表示一个或一类中断已经发生。 INTMSK（中断屏蔽寄存器）：全局中断屏蔽寄存器，用于屏蔽或使能所有中断。 INTPND（中断挂起寄存器）：在SRCPND中的中断经过优先级仲裁后，选中的最高优先级中断的相应位会被置1，CPU将处理该中断。 INTOFFSET（中断偏移寄存器）：用于指示INTPND中哪一位置1，便于查询和清除中断。 3. 状态和控制寄存器 除了上述直接参与中断处理的寄存器外，还有一些状态和控制寄存器在中断处理过程中也发挥着重要作用：

CPSR（当前程序状态寄存器）：包含了处理器的当前状态信息，如中断禁止位（I/F位）、处理器模式等。通过修改CPSR，可以实现中断的使能和禁止，以及处理器模式的切换。 SPSR（程序状态保存寄存器）：当处理器进入异常模式（包括中断模式）时，SPSR会保存进入异常模式前的CPSR的值。在异常处理完毕后，可以通过恢复SPSR的值来恢复处理器的状态。

### 5.ARM内核的常用寄存器及作用

ARM架构中常用的寄存器可以大致分为通用寄存器、专用寄存器和控制寄存器几大类。这些寄存器在ARM处理器的数据处理、函数调用、异常处理等方面起着至关重要的作用。以下是对这些寄存器及其作用的详细介绍：

一、通用寄存器 ARM架构中的通用寄存器通常用于存储临时数据、地址、中间计算结果等。在ARM中，R0到R12是通用寄存器（有些资料中提到共有16个寄存器，但通常R13到R15被视为专用寄存器），它们的具体作用如下：

ARM指令有16个32位通用寄存器，为r0-r15，其中r13为堆栈指针寄存器，r15为指令计算寄存器。实际可以使用的寄存器只有14个。r0-r3一般作为函数参数使用，函数返回值放在r0中。若函数参数超过4个，超过到参数压入堆栈。

R0：通常用于保存函数的返回值。在函数调用中，R0用于接收被调用函数的返回值。 R1-R3：这些寄存器通常用于传递函数参数。在函数调用时，函数的参数会被放置在R1、R2和R3中（取决于参数的数量）。 R4-R8：这些寄存器通常用于保存临时变量和计算中间结果。在程序执行过程中，这些寄存器可以用来暂存需要频繁访问的数据。 二、专用寄存器 ARM架构中的专用寄存器具有特定的用途，它们不直接参与数据运算，但在程序执行和异常处理中起着关键作用。

R13 (SP)：堆栈指针寄存器，用于存储当前模式下的栈顶地址。在函数调用时，SP用于管理栈的使用，确保函数调用的正确执行和返回。 R14 (LR)：链接寄存器，用于存储函数调用之前的返回地址。当函数执行完毕后，LR中的地址会被复制到程序计数器（PC）中，以实现函数的返回。此外，在异常发生时，LR也会保存被异常打断的指令的下一条指令的地址，以便异常处理完成后能够正确返回到异常发生前的状态。 R15 (PC)：程序计数器寄存器，用于存储当前正在执行的指令的地址。PC的值会自动增加以指向下一条要执行的指令。 三、控制寄存器 ARM架构中的控制寄存器主要用于控制CPU的状态和处理异常情况。

CPSR (Current Program Status Register)：当前程序状态寄存器，用于存储当前程序的状态信息。CPSR包含多个字段，如条件标志位（Z、N、C、V等）、控制位（I、F等）和模式位等。这些字段在程序执行过程中起着重要的控制作用。 SPSR (Saved Program Status Register)：保存程序状态寄存器，用于在处理器处理中断时保存中断处理前的程序状态。当中断处理结束后，处理器可以使用SPSR中保存的状态恢复中断前的程序执行状态。

### 6.ARM寻址方式

ARM指令集支持多种寻址方式，以寻找操作数的实际地址，主要包括：

​ 寄存器寻址：操作数直接存放在寄存器中，指令中的地址码字段给出的是寄存器的编号。 立即寻址：操作数就是指令中的一部分，紧跟在操作码之后。 ​ 寄存器移位寻址：操作数是寄存器中的值，但在与第一个操作数结合之前，会先进行移位操作。移位操作可以是逻辑左移（LSL）、逻辑右移（LSR）、算术右移（ASR）等。 ​ 寄存器间接寻址：操作数存放在由寄存器内 容所指定的存储单元中，寄存器中存储的是操作数的地址。 基址寻址：将基址寄存器的内容与指令中给出的偏移量相加，形成操作数的有效地址。 ​ 多寄存器寻址：允许一条指令同时传送多个寄存器值，常用于批量数据传输。 堆栈寻址：使用专门的堆栈指针寄存器指向堆栈区域，通过堆栈操作来存取数据。 ​ 块拷贝寻址：用于将一块数据从存储器的某一位置拷贝到另一位置，一次可以传输多个数据单元。 相对寻址：以程序计数器（PC）的当前值或某个寄存器的值为基准，加上指令中给出的偏移量来形成操作数的地址。

### 7.中断响应执行流程，中断上下文指的什么，保存中断上下文是完成的什么操作，以STM32为例，都有哪些寄存器被保存

断响应执行流程在STM32中通常包括以下步骤：首先，当一个中断事件发生时（如定时器超时、外部引脚电平变化等），中断信号会被触发。STM32的NVIC（嵌套向量中断控制器）会接收到这个信号，并根据优先级决定是否响应此中断。如果响应，处理器会保存当前程序的执行上下文，然后跳转到对应的中断服务程序（ISR）执行中断处理。处理完毕后，处理器会恢复之前保存的上下文，并继续执行原来的程序。

“中断上下文”指的是在中断发生时，CPU寄存器的状态以及程序执行的当前环境信息。这些信息是恢复程序执行所必需的，以便在中断处理完成后能够正确地返回到原来的程序执行点。

保存中断上下文主要是完成将当前CPU寄存器的值以及程序执行的状态信息存储起来，以便在中断处理结束后能够恢复并继续原来的程序执行。这通常涉及到将寄存器的值压入堆栈等操作。

在STM32中，当发生中断时，以下寄存器通常会被保存：

程序计数器（PC）：指示当前程序执行的位置。 状态寄存器（如PSR）：包含处理器的状态信息。 通用寄存器（如R0-R15）：这些寄存器用于存储临时数据和地址。 堆栈指针（SP）：指示堆栈的当前位置，堆栈用于存储临时数据和返回地址。 链接寄存器（LR）：存储了函数调用返回后应该执行的下一条指令的地址。

### 8.STM32 F1和F4的区别

STM32 F1和F4的区别主要体现在以下几个方面：

内核不同：STM32F1采用的是Cortex-M3内核，而STM32F4则采用了更先进的Cortex-M4内核。 主频不同：STM32F1的最高主频为72MHz，而STM32F4的主频可以达到168MHz，处理速度更快。 外设功能：STM32F4相比F1具有更多的外设功能，例如它可以支持多达8路的串口，而STM32F1的串口数量则较少。此外，STM32F4还具有更快的USART和SPI通信速度。 性能：由于STM32F4采用了ART自适应实时加速器，它能够达到相当于FLASH零等待周期的性能，而STM32F1则需要等待周期。这使得STM32F4在性能上更为优越。 功耗：STM32F4的功耗相对更低。例如，STM32F40x的功耗为238uA/Mhz，其中低功耗版本的STM32F401更是低至140uA/Mhz，而STM32F1的功耗则高达421uA/Mhz。 存储器容量：STM32F4的Flash范围从128k至2048K，RAM从64K至256K，提供了更大的存储空间。相比之下，STM32F1的Flash范围较小，为16k至1024k，RAM范围从4k至80K。

### 9.Cotex-M系列使用浮点运算对STM32中断效率会产生什么影响

Cortex-M系列使用浮点运算对STM32中断效率的影响主要体现在处理速度和资源占用上。具体来说：

处理速度：浮点运算通常比整数运算更复杂，需要更多的CPU周期来完成。因此，在中断服务程序中进行浮点运算可能会增加中断的处理时间。这可能导致中断响应时间变长，即从中断触发到中断服务程序开始执行的时间增加。对于需要快速响应的系统，这可能会成为一个问题。 资源占用：浮点运算可能需要更多的内存和处理器资源。在中断处理过程中，如果频繁进行浮点运算，可能会占用更多的堆栈空间，甚至可能导致堆栈溢出等问题。此外，浮点运算也可能增加系统的功耗。

### 10.什么是大小端模式

大小端模式是指各种体系的计算机系统（如PPC、ARM、MIPS等）中采用的字节存储机制，主要分为大端模式和小端模式两种。

大端模式：数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中。这种模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，数据从高位往低位放。 小端模式：数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中。这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低。

### 11.ARM状态

ARM处理器的运行状态主要涉及两个方面：工作模式和工作状态。

首先，关于工作模式，ARM处理器一共有七种，分别是：

用户模式（USR）：正常程序执行模式。 快速中断模式（FIQ）：处理快速中断，支持高速数据传送或通道处理。 外部中断模式（IRQ）：处理普通中断。 特权模式（SVC）：操作系统保护模式，处理软件中断swi reset。 数据访问中止模式（ABT）：当数据或指令预取终止时进入该模式，用于虚拟存储及存储保护。 未定义指令终止模式（UND）：用于支持硬件协处理器的软件仿真。 系统模式（SYS）：用于运行特权级的操作系统任务。 其次，关于工作状态，ARM处理器主要支持两种指令集，因此有两种工作状态：

ARM状态：此时处理器执行32位的字对齐的ARM指令。 Thumb状态：此时处理器执行16位的、半字对齐的Thumb指令。

### 3.常见硬件接口协议/总线

### 1.SPI

SPI（Serial Peripheral Interface，串行外设接口）是一种同步串行通信协议，常用于微控制器（MCU）与外设（如存储器、传感器等）间的通信。以下是一些关于SPI的详细知识：

基本定义： SPI是一种高速、全双工、同步的通信总线，并且在芯片的管脚上只占用四根线，为PCB的布局节省空间，提供方便。这种接口技术由Motorola公司推出，因其简单易用的特性，越来越多的芯片集成了这种通信协议。 系统结构： SPI系统主要由四根线组成：串行时钟线（SCK）、主机输入/从机输出数据线（MISO）、主机输出/从机输入数据线（MOSI）和低电平有效的从机选择线（CS）。 接口特性： SPI是一种主从结构的通信协议，主设备控制通信的时序，从设备响应主设备的命令并与主设备进行数据交换。数据交换以数据帧为基本传输单位，数据帧由一个数据位和可能的附加控制位组成。 工作模式： SPI支持多种工作模式，由时钟极性（CPOL）和时钟相位（CPHA）组成，以适应不同设备的需求。这些模式决定了数据采样和发送的时机。 传输速率： SPI的传输速率较高，可以达到几十兆赫兹甚至上百兆赫兹，具体速率由时钟信号的频率决定。 应用： SPI因其速度快、实现简单等优点，在嵌入式系统设计中广泛应用，如连接传感器、显示器、存储设备和其他外设。特别适用于需要快速数据传输的场景，如实时数据采集和处理。 优缺点： 优点：高速、同步、全双工通信；总线式连接简单；主从机通信模式灵活。 缺点：没有指定的流控制，没有应答机制确认是否接收到数据，因此在数据可靠性上有一定的缺陷。

SPI（Serial Peripheral Interface）的四种工作模式主要是根据其通信方式和时钟信号的特性来定义的。这四种模式包括：

全双工模式： 在此模式下，通信双方可以同时发送和接收数据。 双方都有自己的主从模块，可以在同一时钟信号的作用下进行数据传输。 这种模式的通信速度较快，但需要更多的引脚。 半双工模式： 通信双方只能在不同的时间段发送和接收数据。 双方需要共享时钟信号，一个时间段内一方发送数据，另一方接收数据，并在下一个时间段交换角色。 此模式需要更少的引脚，但通信速度相对较慢。 主从模式（或称为主模式）： 一个设备（主设备）控制通信过程，而另一个或多个设备（从设备）被动响应。 主设备发出时钟信号和选择信号，从设备根据主设备的指令进行发送和接收数据。 在此模式中，主设备与从设备的通信是一对一的关系。 多主模式： 多个设备可以同时充当主设备，互相之间可以发送和接收数据。 每个主设备都有自己的选择信号控制外部设备，并在一个时间段内进行数据传输。 此模式可以实现多个设备的并行通信，但需要复杂的协调机制来避免冲突和数据混乱。 另外，从时钟信号的角度，SPI的四种工作模式还可以通过时钟极性(CPOL)和时钟相位(CPHA)的不同组合来定义，具体如下：

模式0：CPOL=0，CPHA=0。时钟空闲状态为低电平，数据采样发生在时钟的第一个边沿，数据传输发生在时钟的第二个边沿。 模式1：CPOL=0，CPHA=1。时钟空闲状态为低电平，数据采样发生在时钟的第二个边沿，数据传输发生在时钟的第一个边沿。 模式2：CPOL=1，CPHA=0。时钟空闲状态为高电平，数据采样发生在时钟的第一个边沿，数据传输发生在时钟的第二个边沿。 模式3：CPOL=1，CPHA=1。时钟空闲状态为高电平，数据采样发生在时钟的第二个边沿，数据传输发生在时钟的第一个边沿。

### 2.IIC

IIC（Inter-Integrated Circuit，又称为I2C）是一种同步、半双工的串行通信协议，广泛用于连接微控制器和各种外围设备，如传感器、EEPROM和实时时钟等。以下是关于IIC的一些重要知识点：

物理结构： IIC总线由两根通信总线组成：数据线（SDA）和时钟线（SCL）。 这两条线使用的是开漏输出和上拉电阻，以防止短路并允许线与操作。 通信原理： IIC通信是基于主从结构的，即由一个主设备控制通信过程，而从设备则响应主设备的请求。 通信会话由主设备通过发送起始条件开始，并通过发送停止条件结束。 在起始条件后，主设备会发送一个地址帧来选择要与之通信的从设备。 特点与优势： IIC协议支持多个主设备与多个从设备在一条总线上，具有多分支结构。 IIC总线上的设备地址可以是7位或10位，支持挂载的设备数量理论上可以达到1024个，但实际设计中由于总线电容和电压的限制，建议不超过8个设备。 IIC通信具有不同的速度模式，包括标准模式（100kbps）、快速模式（400kbps）、快速模式+（1Mbps）和高速模式（3.4Mbps）。 信号与时序： IIC通信中的关键信号包括起始信号、停止信号、应答信号等，用于控制通信的开始、结束和数据传输的确认。 时钟同步和仲裁机制确保在多个主设备尝试控制总线时能够进行冲突检测和解决。 应用与限制： IIC协议因其简单、灵活和低成本的特点而被广泛应用于各种电子设备中，特别是需要短距离、低速通信的场合。 然而，IIC通信也有一些限制，如通信距离有限（由于电平信号的衰减和噪声干扰）、网络拓扑结构限制（需要主设备进行总线管理）以及一般情况下只支持单主设备和多从设备的连接方式等

### 3.UART

UART（Universal Asynchronous Receiver/Transmitter，通用异步收发器）是一种串行通信接口协议，它允许数据在异步串行方式下进行传输。以下是关于UART的一些关键知识点：

基本定义与工作原理： UART使用两根信号线进行通信：TX（发送）和RX（接收）。数据以异步方式进行传输，即发送方和接收方不需要严格的时钟同步。 UART通信起始位为逻辑低电平，用于标识数据传输的开始。数据按位顺序传输，从最低位到最高位。奇偶校验位用于检测数据传输中的错误。停止位是逻辑高电平，标识数据传输的结束。 数据格式： UART的数据格式通常包括起始位、数据位、奇偶校验位和停止位。数据位可以是5、6、7或8位。奇偶校验位用于错误检测，可以是奇校验或偶校验。停止位表示数据帧的结束。 波特率： 波特率表示每秒钟传送的bit数量，它决定了UART通信的速度。 应用场景： UART广泛应用于各种电子设备和通信系统中，如嵌入式系统、智能家居、工业自动化、车载电子、物联网设备和通信设备。 特点与优势： UART通信简单、可靠且易于实现，适用于短距离通信。 由于其异步特性，不需要严格的时钟同步，使得设备间的连接更加灵活。 与其他通信协议的比较： 与SPI（Serial Peripheral Interface）相比，UART是异步的，而SPI是同步的。UART只需要两根线，而SPI需要四根线。 与IIC相比，UART支持更远的通信距离，并且通常用于不同设备之间的通信，而IIC更常用于同一板卡上不同芯片之间的通信。

### 4.FSMC

FSMC（Flexible Static Memory Controller，灵活的静态存储控制器）是STM32微控制器中的一个特色外设接口。它能够与同步或异步存储器和16位PC存储器卡进行连接，支持包括SRAM、NAND FLASH、NOR FLASH和PSRAM等多种存储器。

以下是关于FSMC接口的一些详细信息：

功能： FSMC可以与不同类型的存储器进行连接，如SRAM、NAND FLASH、NOR FLASH和PSRAM等。 它可以将AHB（Advanced High-performance Bus，高性能总线）传输信号转换到适当的外部设备协议，并满足访问外部设备的时序要求。 工作原理： 所有的外部存储器共享控制器输出的地址、数据和控制信号，但每个外部设备可以通过一个唯一的片选信号加以区分。 FSMC在任一时刻只访问一个外部设备。 FSMC支持不同位宽的异步读写操作，这使得它能够灵活地适应不同的存储器需求。 应用与优势： FSMC使得STM32微控制器能够方便地扩展外部存储器，从而增加存储容量，满足更复杂应用的需求。 通过FSMC接口，可以实现代码从FSMC扩展的外部存储器中直接运行，而不需要首先调入内部SRAM，这提高了运行效率和响应速度。

### 5.CAN

CAN（Controller Area Network，控制器局域网）是一种用于实时应用的串行通讯协议，主要用于汽车和工业自动化领域。以下是关于CAN的相关知识：

基本定义与工作原理： CAN最初是由德国BOSCH公司为汽车工业设计的，现在已广泛应用于各种工业控制系统中。 它是一种多主总线，即总线上的每个节点都有机会成为主节点，向总线发送数据。 CAN总线使用差分信号传输方式，因此可以有效抵抗外界干扰，提高数据传输的稳定性。 特点与优势： 高速率：CAN总线的最高通信速率可达到1Mbps。 多分支结构：总线上可挂接多个设备，设备之间可以通过总线进行数据传输和信息交换。 优先级划分：CAN总线通过报文中的标识符来决定报文的优先级，标识符越小，优先级越高。 非破坏性仲裁：当多个节点同时发送数据时，优先级低的节点会主动停止发送，优先级高的节点可以继续发送，从而确保数据的有序传输。 应用领域： 汽车工业：用于汽车内部的电子控制系统，如发动机管理、车身控制等。 工业自动化：在工业自动化领域，CAN总线被广泛应用于各种设备和系统之间的通信与控制。 其他领域：如航空航天、船舶、医疗设备、智能家居等也有广泛应用。 协议层次结构： CAN协议遵循OSI模型，并进行了相应的简化和优化，主要分为物理层、数据链路层和应用层。其中数据链路层又包括逻辑链路控制子层（LLC）和媒体访问控制子层（MAC）。 报文类型： 数据帧：用于传输数据，包含帧起始、仲裁场、控制场、数据场、CRC场、应答场和帧结束等部分。 远程帧：用于请求发送具有同一标识符的数据帧。 错误帧：由检测到错误的节点发送，用于通知其他节点总线上出现了错误。 过载帧：用于提供接收节点处理前面收到的数据的时间，并防止数据丢失。

### 6.MIPI

MIPI（Mobile Industry Processor Interface）是移动行业处理器接口的缩写，以下是与MIPI接口相关的知识：

定义与用途： MIPI是MIPI联盟发起的为移动应用处理器制定的开放标准。它是一个专门在高速(数据传输)模式下，采用低振幅信号摆幅的接口，特别适用于功率敏感型应用。MIPI接口广泛应用于移动设备中的处理器、摄像头、显示屏等组件之间的通信。 技术特点： MIPI接口采用差分信号传输，设计上需要按照差分设计的一般规则进行严格设计，主要需实现差分阻抗的匹配。MIPI协议规定传输线差分阻抗值为80-125欧姆。 MIPI接口具有速度快、传输数据量大、功耗低和抗干扰能力强的优点。 工作原理： MIPI工作原理包括物理层、数据链路层和应用层。物理层负责数据的物理传输，数据链路层保证数据的可靠传输，应用层负责数据的处理和应用。 MIPI接口支持多种物理层标准，如D-PHY和C-PHY。D-PHY使用LVDS技术进行数据传输，速率可达4Gbps；C-PHY使用PAM技术，速率可达3Gbps。 应用层协议： MIPI接口在应用层可以根据具体应用场景选择不同的协议，如CSI-2（Camera Serial Interface-2）用于摄像头数据传输，DSI（Display Serial Interface）用于显示屏数据传输。 发展趋势： MIPI接口不仅在智能手机、平板电脑等移动设备中有广泛应用，还扩展到汽车、物联网等领域，如高分辨率相机、激光雷达、信息显示等。

### 7.DMA

DMA（Direct Memory Access，直接内存访问）是一种技术，它允许硬件子系统（如磁盘控制器、声卡、网卡等）直接读写系统内存，而不需要通过CPU进行中介。使用DMA，数据可以直接在内存和外设之间传输，从而大大提高了数据传输的效率，降低了CPU的负载。

以下是关于DMA的一些关键知识点：

基本定义： DMA 是一种不经过 CPU 而直接从内存存取数据的数据交换模式。在 DMA 模式下，CPU 只须向 DMA 控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，这样就很大程度上减轻了 CPU 资源占有率，可以大大节省系统资源。 工作原理： 在 DMA 传输中，设备向 DMA 控制器请求传输数据。 DMA 控制器向 CPU 发送一个请求信号，请求占用总线。 CPU 响应请求，让出总线控制权，并进入挂起状态。 DMA 控制器接管总线，控制内存与设备之间的数据交换。 数据传输完成后，DMA 控制器通知 CPU，CPU 恢复对总线的控制。 优点： 提高了数据传输效率，因为数据直接在内存和设备之间传输，不需要经过 CPU。 降低了 CPU 的负载，使 CPU 可以处理其他任务。

### 8.ADC

ADC（Analog-to-Digital Converter，模拟到数字转换器）是一种电子设备，用于将连续的模拟信号转换为离散的数字信号，以便于数字电路或计算机系统进行处理和分析。

以下是关于ADC的一些关键知识点：

基本定义： ADC是一种电子组件，它的功能是将连续变化的模拟信号转换为一系列等效的数字值。这些数字值可以表示模拟信号的幅度、频率或其他特性。 工作原理： ADC通过定期采样模拟信号，并将每个采样点的电压或电流值转换为一个相应的数字编码。这个过程通常包括采样、量化和编码三个步骤。 采样是指在特定的时间点上捕捉模拟信号的瞬时值。 量化是将每个采样点的连续电压值映射到最接近的离散电平上。 编码则是将这些离散电平转换为二进制或其他数字格式。 性能指标： 分辨率：表示ADC能够区分的最小模拟信号变化量，通常以位数（如8位、10位、12位等）来衡量。位数越高，分辨率越高，转换结果的精度也越高。 采样率：表示ADC每秒采样的次数，通常以赫兹（Hz）为单位。采样率越高，能够捕捉到的模拟信号动态变化越准确。 转换速度：指ADC完成一次模拟到数字转换所需的时间。转换速度越快，ADC越能够实时地反映模拟信号的变化。 应用场景： 音频和视频处理：ADC用于将声音和图像等模拟信号转换为数字信号，以便于存储、传输和处理。 传感器接口：许多传感器输出的是模拟信号，ADC可以将这些信号转换为数字形式，供微处理器或其他数字系统使用。 通信系统：在无线通信和有线通信系统中，ADC用于将接收到的模拟信号转换为数字信号，以便进行后续的数字信号处理。 类型： 逐次逼近型ADC（SAR ADC）：通过逐次逼近算法来逼近输入模拟信号的数值。 积分型ADC（Integrating ADC）：通过对输入模拟信号进行积分来转换为数字信号。 流水线型ADC（Pipeline ADC）：采用多级结构，每级完成一部分转换工作，最后合并得到完整的数字输出。 Δ-Σ型ADC（Delta-Sigma ADC）：利用过采样和噪声整形技术来提高转换精度和信噪比。

### 9.RGB接口

RGB接口是一种用于传输红、绿、蓝三原色视频信号的接口。它是工业界的一种颜色标准，通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色。RGB接口属于色差输入，是专业绘图等场合常用的接口，可以传输高质量的图像信号。

关于RGB接口，有以下几点值得注意：

定义与用途： RGB接口是分三原色输入的视频接口，用于传输高质量的图像数据。 它能够传输专业绘图等需要的高质量图像信号。 技术特点： RGB接口占用的资源较多，因此其LCD刷新率非常快，软件控制也比较简单。 RGB接口的显示数据不需要写入内存进行处理，可以直接写入LCD进行显示，所以响应速度和刷新速度都比其他某些接口快很多。 并行传输方式： 在并行传输方式中，每一位基色信号数据都使用一条单独的数据线进行传输。例如，对于8位液晶面板，R、G、B三个子像素分别用8位的数据量来表示，因此RGB数据线一共有24条。 应用领域： RGB接口在工业仪器仪表、智能制造、工业安全监控以及增强现实(AR)技术等领域有广泛应用。 发展趋势： 随着5G技术的普及和应用，RGB接口将更加稳定和高效地工作。 RGB接口有望与人工智能和大数据技术融合，为工业领域带来更多的智能化解决方案。

## 4.操作系统（RTOS)

### 1.rtos的任务调度方式

RTOS（实时操作系统）的任务调度方式是其核心功能之一，负责管理和调度不同任务的执行顺序和优先级，以满足实时性要求。以下是RTOS中几种常用的任务调度方式：

1. 优先级调度（Priority-based Scheduling）

基本原理：每个任务都被分配一个优先级，RTOS保证任何时候处于最高优先级的任务处于运行状态。当多个任务就绪时，RTOS会选择优先级最高的任务执行。

优先级抢占：如果高优先级的任务就绪，而当前正在执行的任务优先级较低，RTOS会立即中断低优先级任务的执行，转而执行高优先级的任务。这种机制确保了高优先级任务能够及时响应。

应用场景：适用于对实时性要求较高的场合，如工业自动化、航空航天等领域。

1. 时间片轮转调度（Round-Robin Scheduling）

基本原理：每个任务被分配一个固定的时间片（time slice），当时间片用完后，该任务会被挂起，然后下一个任务开始执行。当所有任务都执行完一轮后，再次按顺序执行，直到所有任务完成。

特点：保证了任务的公平执行，避免了某个任务长时间占用CPU资源。

应用场景：适用于对实时性要求不高的场合，或者与优先级调度混合使用，以平衡任务的公平性和实时性。

1. 抢占式调度（Preemptive Scheduling）

基本原理：允许任务在任意时间点抢占CPU。当一个更高优先级的任务到达时，它可以立即抢占正在执行的任务的CPU资源，并执行自己。

优点：保证了高优先级任务的及时响应。

缺点：可能会增加任务切换的开销，因为每次任务切换都需要保存和恢复任务的上下文信息。

应用场景：广泛应用于实时性要求高的RTOS中。

\4. 合作式调度（Cooperative Scheduling）

基本原理：任务必须主动释放CPU控制权，才能让其他任务执行。每个任务都有一个执行时间限制，如果任务未能在规定时间内主动放弃CPU，则会导致系统无响应。

优点：实现简单，避免了任务抢占带来的开销。

缺点：如果任务不遵守合作规则，可能会导致系统无响应。

应用场景：适用于资源有限的嵌入式系统，或者对实时性要求不高的场合。

\5. 其他调度方式

最短剩余时间优先调度（Shortest Job First, SJF）：一种动态优先级调度方法，每个任务的优先级根据其剩余执行时间来确定，剩余执行时间越短，优先级越高。

最早截止时间优先调度（Earliest Deadline First, EDF）：一种静态优先级调度方法，每个任务的优先级根据其截止时间来确定，截止时间越早，优先级越高。

  

### 2.内存管理heap4，什么时候合并内存碎片

在FreeRTOS的内存管理系统中，heap4是一种常用的内存堆管理方式，它采用了首次适配（first-fit）算法来分配内存，并且具备合并相邻空闲内存块以减少内存碎片的功能。关于heap4何时合并内存碎片的问题，可以归纳如下：

合并内存碎片的时机 内存释放时： 当一个内存块被释放（即使用pvPortFree或类似的函数）并重新变为空闲状态时，heap4会检查该空闲块是否与相邻的空闲块地址连续。如果是，则将它们合并成一个更大的空闲内存块，以减少内存碎片。 内存分配后（间接影响）： 虽然直接的内存合并发生在内存释放时，但内存分配操作也会间接影响内存碎片的合并。当内存块被分配后，如果剩余的空闲部分足够大，它会被保留为一个新的空闲块，并可能在未来与相邻的空闲块合并。 合并过程 查找相邻空闲块：释放内存块时，heap4会遍历空闲块链表，找到释放块的前一个和后一个空闲块（如果存在）。 检查地址连续性：通过比较内存地址，检查释放块与相邻空闲块是否连续。 合并操作：如果地址连续，则将相邻的空闲块合并为一个更大的空闲块，并更新空闲块链表。

### 3.FreeRTOS内存管理

一、内存管理方式 堆（Heap）： 堆是一块空闲的内存区域，用于动态内存分配。FreeRTOS提供了多种堆内存管理方法，如heap_1、heap_2、heap_3、heap_4和heap_5，这些方法通过不同的算法来管理内存的申请和释放。 heap_1：最简单的方法，动态内存一旦申请就不允许释放，适用于系统启动阶段就完成资源创建且不需要删除的嵌入式应用。 heap_2：利用最佳匹配算法（best fit）支持内存释放，但不支持内存碎片整理，容易产生内存碎片。 heap_3：对标准C库中的malloc和free函数进行简单封装，额外做了线程保护，内存堆大小由启动文件设置。 heap_4：使用首次适应算法（first fit）分配内存，并支持内存碎片的回收，能有效减少内存碎片问题。 heap_5：与heap_4类似，但允许内存堆跨越多个不连续的内存段，使用前需要通过vPortDefineHeapRegions函数进行初始化。 栈（Stack）： 栈用于存储函数调用时的局部变量和当前程序的环境。在FreeRTOS中，每个任务都有自己的栈，栈的大小可以在任务创建时指定。

### 3.任务（线程）间通信方法

RTOS任务（线程）间通信的方法主要包括以下几种：

消息队列：这是一种用于在任务与任务之间、中断与任务之间传递信息的数据结构。消息队列支持超时机制，允许任务等待特定消息的到来或者在规定时间内尝试读取消息。 信号量：信号量是一个用于同步某个任务与单个事件或任务的工具。最基本的信号量是二值信号量，用于实现简单的等待-通知机制。此外，还有计数信号量，可以处理信号的积压问题，以及互斥锁（也称为互斥信号量），它是一种特殊类型的信号量，用于保护共享资源，确保任何时候只有一个任务可以访问该资源。 事件标志组：主要用于一个任务与多个事件的同步，或者一个任务与多个任务之间的同步。它们允许任务等待多个事件中的任何一个发生。 任务通知：具有32位的消息通知值，可以减少RAM的使用，运行效率较高。当一个任务完成了某项工作或者发生了某个事件时，它可以通知另一个或多个等待该通知的任务。

### 4.进程和线程的区别

进程和线程是操作系统中重要的概念，二者具有以下区别：

资源分配：进程是操作系统资源分配的基本单位。每个进程都有独立的代码和数据空间（程序上下文），每当程序切换时，会有较大的开销。相对地，线程可以看作轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器(PC)，线程之间切换的开销较小。 执行方式：如果一个进程内有多个线程，这些线程会共享该进程的资源，并可以同时执行多条线程。线程是处理器调度的基本单位，而进程不是。每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口，但线程必须依存在应用程序中，由应用程序提供多个线程执行控制。

### 5.互斥量和信号量的区别

互斥量和信号量的区别主要体现在以下几个方面：

用途： 互斥量主要用于线程的互斥，确保同一时间只有一个线程可以访问某一资源，具有唯一性和排它性。它不支持多个线程同时访问一个资源。 信号量则用于线程的同步。在大多数情况下，同步已经实现了互斥，尤其是所有写入资源的情况必定是互斥的。信号量可以允许多个线程访问同一资源，但会控制同时访问的线程数量。 值域： 互斥量的值只能为0或1，表示资源被占用或未被占用。 信号量的值可以为非负整数，表示可同时访问资源的线程数量。 操作方式： 互斥量的加锁和解锁必须由同一线程分别对应使用，即一个线程在获取互斥量（加锁）后，必须负责释放（解锁）它。 信号量可以由一个线程释放，另一个线程得到。这意味着一个线程可以释放信号量，从而允许其他线程获取它。

### 6.优先级翻转，如何避免优先级翻转

RTOS中的优先级翻转是一个关键问题，它发生在当一个高优先级的任务被低优先级的任务阻塞时，导致高优先级的任务无法及时执行。为了避免RTOS中的优先级翻转问题，可以采取以下几种策略：

​ 优先级继承：当一个高优先级任务H因为等待低优先级任务L持有的资源而被阻塞时，L临时继承H的优先级，直到它释放资源。这种方法能够确保高优先级任务不会被低优先级的任务长时间阻塞。 ​ 优先级天花板：为每个互斥锁设置一个优先级天花板，即所有任务中最高的优先级。任何持有该锁的任务将运行在这个优先级上，直到释放锁。这种方法通过提升低优先级任务的执行级别来避免中优先级任务的干扰。 避免共享资源：通过设计来减少或避免高优先级和低优先级任务之间共享资源的需要。这可以通过合理的任务划分和系统设计来实现，从而降低优先级翻转的风险。

### 7.STM32任务切换为什么用PendSV

STM32任务切换使用PendSV的主要原因有以下几点：

可悬起异常：PendSV是一个可悬起的异常，这意味着它可以在其他重要任务完成后才执行，从而实现非抢占式的任务切换，确保系统的稳定性。 最低优先级设置：PendSV可以被设置为最低的异常优先级。这种设置允许其他高优先级的异常或中断先被处理，避免了任务切换打断正在运行的中断事件，保证了系统的实时性。 灵活性：PendSV异常的使用提供了任务切换的灵活性。当系统需要执行上下文切换时，它会设置PendSV的挂起状态，在PendSV异常内执行上下文切换，这样可以将上下文切换的请求延迟到所有其他中断处理完成后执行。 利用系统滴答定时器：在接收到系统调用（如任务切换函数taskYIELD()）或系统滴答定时器（SysTick）中断时，可以通过SVC（中断控制和状态寄存器ICSR）挂起PendSV，在空闲状态执行PendSV中实现任务切换操作。

### 8.对于临界区数据的处理，使用互斥锁和自己通过条件来判断，哪样更好，为什么？

使用互斥锁是处理临界区数据的更佳选择。它提供了强制性的同步机制，简化了代码逻辑，并提高了代码的可移植性。然而，在某些特定场景下，如果开发者对同步需求有深入的理解，并且能够通过自定义条件判断实现更高的性能和更精细的控制，那么自定义条件判断也可能是一个合理的选择。但需要注意的是，这种方法通常要求开发者具备更高的编程技巧和经验。

### 5.Linux嵌入式

### 1.open或read系统调用的全流程

open系统调用的全流程 应用层调用： 在应用层，程序通过调用C标准库中的open函数来尝试打开一个文件。这个函数的调用实际上是一个对系统调用的封装。 系统调用准备： open函数准备系统调用的参数，包括文件路径、打开模式（如只读、只写、读写等）以及其他可能的选项（如文件权限、文件创建标志等）。 触发中断： 在大多数操作系统中，如Linux，系统调用通过触发中断来从用户态切换到内核态。在ARM架构中，这通常通过swi（Software Interrupt）汇编指令完成，而在x86架构中，则可能是通过int 0x80或syscall指令。 中断处理： 中断处理程序接收到系统调用请求后，会根据系统调用号（对于open系统调用，在Linux中通常是一个特定的数值，如5）查找系统调用表，并跳转到对应的内核函数（如sys_open）执行。 内核处理： sys_open函数在内核中执行，负责查找和打开文件。这包括： 将文件路径从用户空间复制到内核空间。 根据路径查找文件系统中的文件。 分配一个文件描述符（如果文件成功打开）。 更新内核中的文件描述符表和其他相关数据结构。 结果返回： 如果文件成功打开，sys_open会返回一个非负的文件描述符给应用程序。否则，会返回一个错误码。 切换回用户态： 系统调用完成后，CPU从内核态切换回用户态，并将结果（文件描述符或错误码）返回给应用层。

### 2.说说u-boot启动流程。

硬件上电： 当硬件上电后，CPU开始执行芯片上的启动加载程序（如ROM中的启动加载程序）。 加载U-Boot： 启动加载程序将控制权转交给U-Boot。U-Boot被加载到内存中，这通常涉及到从某种存储介质（如Flash、SD卡等）中读取U-Boot的二进制镜像。 初始化过程： U-Boot在内存中执行初始化过程，包括初始化CPU、内存、外设等硬件，并设置基本的系统环境。 加载并解析设备树文件： U-Boot加载并解析设备树文件（通常是.dtb文件），这个文件描述了系统的硬件结构和信息，对于嵌入式系统尤为重要。 加载内核镜像： U-Boot从存储介质（如Flash、SD卡、TFTP服务器等）加载内核镜像（如Linux内核）到内存中。 传递参数给内核： U-Boot将操作系统启动所需的参数（如内核命令行参数）传递给内核。 跳转到内核入口点： U-Boot跳转到内核的入口点，开始执行内核代码。内核接管控制权后，进行进一步的初始化，如挂载根文件系统、启动init进程等。

### 2.Bootloader两个阶段

Bootloader的启动过程通常分为两个阶段：Stage 1（第一阶段）和Stage 2（第二阶段）。这两个阶段各自承担着不同的职责和任务，以确保系统能够顺利启动。 Stae 1（第一阶段） 主要任务： 硬件设备初始化：Bootloader的第一阶段负责初始化计算机或嵌入式系统的硬件设备，包括处理器、内存控制器、外部设备等。这是启动过程中非常关键的一步，因为后续的操作都依赖于这些硬件设备的正常工作。 为Stage 2准备RAM空间：在Stage 1中，Bootloader会为加载Stage 2而准备好内存空间（RAM）。这是通过栈（stack）的方式进行的，以确保有足够的空间来加载和运行Stage 2的代码。 加载Stage 2：Bootloader的Stage 1会从预定义的存储设备（例如硬盘、闪存）中读取Stage 2的引导程序，并将其加载到预先分配的内存空间（RAM）中。这个过程中，Bootloader需要能够识别并访问存储设备上的数据。 设置堆栈：Bootloader在加载Stage 2之前会设置好堆栈指针，以确保在后续的执行过程中能正确地进行函数调用和返回操作。堆栈是计算机程序运行时用于存储临时数据的一种数据结构，对于程序的正常运行至关重要。 跳转到Stage 2的C入口点：在加载完Stage 2之后，Bootloader会将控制权转移到Stage 2的C入口点，即Stage 2中的C语言代码执行的起始位置。这样，系统就可以开始执行Stage 2中的代码了。 实现方式： 依赖于CPU体系结构的代码，比如设备初始化代码等，通常都放在Stage 1中，而且通常都用汇编语言来实现，以达到短小精悍和高效的目的。

Stage 2（第二阶段） 主要任务： 初始化硬件设备：Bootloader的Stage 2会进一步初始化硬件设备，例如外部设备（键盘、鼠标、显示器等）和各种总线（如USB、PCI等）。这些设备在Stage 1中可能已经被初步初始化，但Stage 2会进行更详细和全面的初始化工作。 检测系统内存映射（Memory Map）：Stage 2会对系统的内存进行检测，确定可用的内存容量和位置，并为操作系统的加载做好准备。内存映射是操作系统管理内存资源的基础，对于系统的稳定性和性能至关重要。 从存储设备读取内核映像和根文件系统映像：Bootloader的Stage 2会从预定义的存储设备中（通常是硬盘或闪存）读取操作系统内核映像和根文件系统映像到事先准备好的内存区域。这些映像文件包含了操作系统运行所需的所有数据和代码。 为内核设置启动参数：Stage 2有责任为内核设置启动参数，这些参数包括内核命令行参数、映像加载地址等，以便操作系统能够正确地进行初始化和配置。启动参数是操作系统启动过程中非常重要的一部分，它们决定了操作系统的行为和特性。 调用内核：最后，Bootloader的Stage 2会通过跳转或者函数调用的方式将控制权转交给操作系统内核的入口点，以启动操作系统的执行。一旦内核开始执行，Bootloader的任务就完成了。 实现方式： Stage 2则通常用C语言来实现，这样可以实现更复杂的功能，而且代码具有更好的可读性和可移植性。 Bootloader的第一个阶段之所以需要足够小，主要是出于以下几个方面的考虑： 1. 硬件限制 存储介质限制：在嵌入式系统或某些特定硬件平台上，存储介质（如ROM、Flash等）的容量可能非常有限。Bootloader作为系统启动时的第一个执行程序，需要被存储在这些介质上。因此，为了节省存储空间，Bootloader的第一个阶段必须足够小。 内存限制：在系统启动初期，可用的内存资源也非常有限。Bootloader的第一个阶段需要在有限的内存环境中运行，并完成必要的初始化任务。因此，其大小必须受到严格控制，以确保不会超出内存的限制。 2. 执行效率 快速启动：系统启动过程中，用户期望能够快速看到启动界面并进入操作系统。Bootloader的第一个阶段作为启动流程的开始，其执行速度直接影响到整个启动过程的效率。因此，通过减小其大小，可以缩短其执行时间，从而加快系统启动速度。 减少资源占用：较小的代码体积意味着在执行过程中占用的CPU、内存等资源也会相应减少。这对于资源受限的嵌入式系统或老旧硬件平台尤为重要。 3. 功能需求 基本初始化：Bootloader的第一个阶段主要负责完成基本的硬件初始化工作，如CPU、内存、中断等的初始化。这些工作对于后续的启动流程至关重要，但并不需要过于复杂的代码来实现。因此，通过精简代码，可以在满足功能需求的同时保持较小的体积。 为第二阶段准备：Bootloader的第一个阶段还需要为第二阶段的执行做好准备工作，如加载第二阶段的代码到内存中、设置堆栈等。这些工作虽然重要，但并不需要过多的代码来实现。因此，第一个阶段的代码大小可以进一步得到控制。 4. 可移植性和可维护性 简化代码结构：较小的代码体积有助于简化Bootloader的代码结构，使其更加清晰、易于理解和维护。这对于提高Bootloader的可移植性和可维护性具有重要意义。 降低错误风险：较小的代码体积也意味着在编写和调试过程中可能引入的错误也会相应减少。这有助于降低Bootloader在启动过程中出错的风险，提高系统的稳定性和可靠性。

### 4.Linux的内存管理

内存管理的核心概念 物理内存： 物理内存是指系统硬件提供的内存大小，是真正的内存资源。 虚拟内存： 虚拟内存是为了满足物理内存的不足而提出的策略，它利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 在Linux中，每个进程都拥有独立的虚拟地址空间，这有助于减少内存中的出错，并提升系统的安全性。 二、内存管理的机制 内存分配与释放： Linux内核使用多种机制来管理内存的分配和释放，如伙伴系统（Buddy System）、Slab分配器等。 伙伴系统是一种数据结构，它将内存分为不同的大小类别（称为内存块或页），并动态地分割和合并这些块以满足进程的内存请求。 Slab分配器特别适用于分配和释放小块内存，通过缓存对象来减少碎片并提高分配效率。 内存映射： Linux通过内存映射机制将文件或设备映射到进程的地址空间中，这样进程就可以直接通过地址空间访问这些文件或设备，而无需进行传统的读写系统调用。 交换空间（Swap Space）： 当物理内存不足时，Linux内核会使用交换空间来临时存储不活跃的内存页，从而为更重要的内存请求腾出空间。 交换空间的使用可以提高系统的内存利用率，但频繁的交换操作会导致系统性能下降。 OOM Killer（Out of Memory Killer）： 在极端情况下，当系统内存耗尽且无法通过其他方式回收内存时，Linux内核会触发OOM Killer。OOM Killer会选择并终止一些进程来释放内存，以避免系统崩溃。 三、内存管理的优化策略 内存压缩： 为了提高内存使用效率，Linux内核会定期进行内存压缩。这个过程涉及到将内存中的页框重新排列，使得相同大小的页框聚集在一起，从而更容易找到足够大的连续内存块来满足分配请求。 大页内存： 在一些需要大内存连续空间的应用中，使用大页内存可以提高性能，减少内存碎片。Linux提供了透明大页等特性来自动将小页内存转换为大页内存。 内存回收策略： Linux内核提供了多种内存回收策略，如延迟页面回收和直接回收等。这些策略可以根据具体需求进行调整，以优化系统的内存使用。

### 3.linux中的线程一般是怎么调度的？

在Linux中，线程的调度是由内核管理的过程，主要负责根据预定义的调度策略和优先级来决定哪个线程在给定的时间点运行。Linux提供了几种线程调度策略，包括SCHED_OTHER（默认的分时调度策略，基于时间片轮转）、SCHED_FIFO（先进先出策略，优先级高的线程会一直运行，直到它主动放弃CPU）、SCHED_RR（基于时间片轮转的策略，优先级高的线程运行一段时间后被抢占）等。此外，还有实时调度策略如SCHED_DEADLINE，它主要用于对时间敏感的应用。

线程的调度过程涉及到线程的优先级，每个线程都被分配了一个优先级，优先级的范围通常是0-139，其中0是最高优先级，139是最低优先级。优先级高的线程将优先获得CPU的使用权。

Linux内核还支持线程亲和性，允许将线程绑定到特定的CPU核心，以提高缓存利用和性能。

在具体实现上，Linux内核的调度器会根据线程的优先级和调度策略来决定哪个线程应该被执行。调度器会综合考虑线程的优先级、时间片等因素，以确保系统的并发能力、公平性和响应性。

### 4.如果现在是一个单核的CPU，那么多个线程是按什么顺序去运行的？也就是线程的系统调度？

在单核CPU上，多个线程的运行实际上是通过时间片轮转的方式来调度的。由于单核CPU同一时间只能处理一个线程，操作系统会将CPU时间切分成很短的时间片，并分配给每个线程。线程之间会按照调度算法快速切换，使得每个线程都有机会运行，从而给用户一种多个线程同时运行的错觉。

具体来说，线程的调度顺序主要取决于操作系统的调度策略和线程的优先级。操作系统会根据这些因素来分配时间片，确定哪个线程在什么时候运行。例如，优先级高的线程可能会获得更多的CPU时间，而优先级低的线程则可能等待更长时间才能获得CPU时间。

需要注意的是，线程的调度是一个复杂的过程，涉及到多种因素，包括线程的优先级、时间片的大小、线程的I/O操作等。此外，不同的操作系统和调度算法可能会有不同的调度方式和效果。

总的来说，在单核CPU上，多个线程是通过时间片轮转和优先级调度等方式来运行的，以实现并发执行的效果。这种机制确保了即使只有一个CPU核心，也能高效地处理多个线程。

### 5.如果现在多个线程，怎么确定哪一个会先被执行？

当存在多个线程时，确定哪一个会先被执行主要取决于以下几个因素：

线程的优先级：操作系统通常会为每个线程分配一个优先级。优先级高的线程往往会被优先执行。这种优先级可以由程序员在编写程序时设定，也可以根据线程的运行状态和系统的调度策略动态调整。 调度策略：不同的操作系统可能采用不同的调度策略，如时间片轮转、优先级调度等。这些策略会影响线程的执行顺序。例如，在时间片轮转策略中，每个线程会被分配一个时间片，当时间片用完时，当前线程会被暂停，换下一个线程执行。而在优先级调度中，优先级高的线程会优先获得CPU的使用权。 线程的状态：线程的状态（如就绪、等待、阻塞等）也会影响其执行顺序。例如，一个处于阻塞状态的线程会暂停执行，直到某个条件满足（如获取到所需的资源）后才会变为就绪状态，等待被调度执行。 操作系统的具体实现：不同的操作系统或不同的调度器实现可能会有不同的行为。因此，具体的执行顺序还可能受到操作系统内部算法和实现细节的影响。

### 6.多个进程在获取不到锁的时候会进入什么状态？

当多个进程尝试获取锁但失败时，它们会进入阻塞状态。在这种状态下，进程会等待锁变得可用。一旦锁被释放，操作系统会根据其调度策略唤醒等待的进程，使它们有机会重新尝试获取锁并执行相应的任务。

这一信息是基于操作系统和并发编程的基本原理，这些原理在多个权威教材、专业网站以及技术文档中都有详细阐述。虽然具体的实现细节可能因操作系统和编程语言的不同而有所差异，但阻塞状态是并发控制中一种常见的现象，用于处理资源争用和同步问题。

### 7.假设一个低优先的进程A获取先到锁，高优先级的进程B获取不到锁，那高优先级进程B的进行也会阻塞吗？

如果低优先级的进程A已经获取了一个锁，而高优先级的进程B尝试获取同一个锁时，进程B将会因为无法获取锁而被阻塞，即使它的优先级高于进程A。这是因为锁机制是为了保护共享资源，确保在同一时间只有一个进程可以访问或修改这些资源，从而防止数据不一致或其他并发问题。

锁的获取并不考虑进程的优先级；它仅仅是一个控制访问共享资源的机制。因此，不论进程的优先级如何，只要锁被其他进程持有，任何尝试获取该锁的进程都将被阻塞，直到锁被释放。

### 8.那如果还有一个任务C，优先级介于A和B之间，那么C任务会去抢占CPU资源吗？

在操作系统中，任务的调度不仅仅取决于优先级，还受到当前系统状态、任务的就绪状态以及其他调度因素的影响。当任务C的优先级介于A和B之间时，是否会抢占CPU资源取决于几个关键因素：

就绪状态：首先，任务C必须是处于就绪状态，即它已经准备好执行但尚未被调度。如果任务C不在就绪队列中，那么它不会抢占CPU。 调度策略：操作系统的调度策略决定了哪个任务将获得CPU。常见的调度策略包括先来先服务（FCFS）、最短进程优先（SPF）、最短剩余时间优先（SRTF）、优先级调度等。如果系统采用优先级调度，并且任务C的优先级高于当前正在运行的任务（如任务A），那么任务C有可能在任务A释放CPU时抢占CPU资源。 优先级反转保护：在某些系统中，为了防止优先级反转问题（即低优先级任务阻塞高优先级任务），可能会实施特殊的调度策略，如优先级继承或优先级天花板协议。这些策略可以临时提升被阻塞的高优先级任务的优先级，或者降低持有锁的低优先级任务的优先级。 锁和同步机制：如果任务A持有锁，并且任务B（高优先级）和任务C（中优先级）都在等待该锁，那么即使任务C的优先级高于任务A，它也无法执行，直到任务A释放锁。锁的持有与任务的优先级无关，它阻止了其他任务访问受保护的资源，直到锁被释放。 系统负载和上下文切换开销：即使任务C的优先级高于当前运行的任务，操作系统也可能因为上下文切换的开销而犹豫是否立即调度任务C，特别是在系统负载较高时。

### 9.linux用户态和内核态区别

Linux用户态和内核态的主要区别体现在程序运行的权限和访问硬件资源的方式上。

权限级别： 用户态：程序运行在较低的权限级别，不能直接访问系统底层的资源，如硬件设备和内核态的代码。用户态下的程序主要执行应用程序逻辑。 内核态：操作系统运行在较高的权限级别，能够直接访问硬件设备和系统资源，并能执行操作系统内核的代码。内核态下的程序主要执行底层操作，如驱动程序、系统服务等。 资源访问： 用户态：程序需要通过系统调用来请求操作系统执行相关操作，不能直接访问底层资源。 内核态：可以直接访问和管理硬件设备和系统资源。 执行内容： 用户态：主要执行应用程序代码，如文本编辑器、浏览器等。 内核态：主要执行操作系统内核代码，管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性。 安全性： 分隔用户态和内核态有助于提升系统的安全性。内核态的代码受到更严格的保护，以防止恶意软件或用户错误导致系统崩溃或数据损坏。

### 10.Linux在用户态开发中程序跑飞，出现段错误等情况，你通过什么方式去定位？

在Linux用户态开发中，如果程序出现跑飞或段错误等情况，可以通过以下几种方式来定位问题：

使用调试器：可以使用如gdb这样的调试器来定位段错误。在编译时，使用-g选项来生成调试信息。当程序发生段错误时，调试器会停止程序，并提供引发段错误的位置信息，包括源代码位置、函数调用栈等，这有助于精确地找到问题所在。 内存检查工具：利用内存检查工具如Valgrind，它可以帮助发现内存错误，包括段错误。Valgrind能检测应用程序中的内存访问错误和内存泄漏等问题，并提供详细的报告来指导修复工作。 查看日志：在应用程序中添加适当的日志输出，比如在关键的代码路径中添加打印语句来跟踪段错误。将日志输出到文件中，以便在发生段错误时查看日志信息，这有助于跟踪和定位问题。 信号处理和addr2line工具：通过编程捕获SIGSEGV信号，当应用程序发生段错误时，会自动跳转到预设的信号处理函数进行处理。此外，可以利用addr2line工具将给定的地址转换为对应的源代码位置，这可以快速定位引发段错误的具体代码行。 其他工具：还有一些其他工具如NetHogs等，虽然它主要用于监控网络带宽使用率，但在某些情况下也可能帮助识别异常的网络行为，间接辅助定位某些类型的问题。不过，它并不是直接针对段错误的定位工具

### 12.程序分成那几个段吗？

程序主要分成以下几个段：

代码段：也称为文本段，主要存放程序的指令代码。这部分通常是只读的，并被映射到内存中。在一些情况下，局部变量也可能存放在代码段中。 数据段：包含程序中已初始化且初值不为0的全局变量和静态变量。数据段又分为初始化的数据段（包含程序中明确赋初值的变量）和未初始化的数据段（亦称BSS段，存放未初始化或初始化为0的全局和静态变量）。数据段在程序运行时是可写的。 BSS段：是英文Block Started by Symbol的简称，属于静态内存分配。它通常用来存放程序中未初始化的全局变量和静态变量。在程序载入时，内核会将这些变量的值清0。 堆（heap）：用于动态内存分配。程序在运行时使用malloc等函数动态分配的内存空间位于堆中。堆的大小并不固定，可以根据需要动态增长或缩小。 栈（stack）：用于存放函数的局部变量、函数调用的返回地址以及函数调用的参数等。栈是一种后进先出（LIFO）的数据结构，其空间从高地址向低地址增长。